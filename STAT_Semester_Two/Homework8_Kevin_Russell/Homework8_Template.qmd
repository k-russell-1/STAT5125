---
title: "Homework 8 Solutions"
author: Kevin Russell
format: 
  html:
    embed-resources: true
---

## Problem 1 [43 Points Total]

Consider the following "lazy cow" variant of cow patty bingo as described in Week 8 Lecture 1.

Instead of each square on the field being equally likely to be chosen by the cow, we now assume that the cow is more likely to choose points that are close to the (0,0) square.

Specifically, we assume that the probability of a particular square being chosen by the cow is proportional to $e^{-\sqrt{x^2 + y^2}}$, where $x$ and $y$ denote the coordinates of the square in the grid.

### Part A [8 Points]

Modify the following function so the squares of a particular square being chosen by the cow is proportional to $e^{-0.5\sqrt{x^2 + y^2}}$.


```{r}
library(tidyverse)
theme_set(theme_bw())

# MODIFY THE FOLLOWING FUNCTION

cow_patty_bingo_lazy <- function(seed){
  set.seed(seed)
  
  cow_grid <- expand_grid(x = 1:10,
                        y = 1:10) |>
  mutate(square_id = 1:n(),
         .before = 1) |>
  mutate(prob2 = exp(1)^(-0.5 * sqrt(x^2 + y^2)))
  
  mult = 1 / sum(cow_grid$prob2)  
  
  cow_grid <- cow_grid |>
    mutate(prob2 = mult * prob2)

  winner <- cow_grid |>
    pull(square_id) |>
    sample(1,
           prob = cow_grid |> pull(prob2))
  
  cow_grid |>
    mutate(winner = if_else(square_id == winner,
                            TRUE,
                            FALSE))
}
```


### Part B [5 Points]

Modify the plotting code from the lecture to visualize running three games of cow patty Bingo with the lazy cow. Use seeds 1, 2, and 3.

```{r}
cow_grid_winner <- cow_patty_bingo_lazy(seed = 1)

cow_grid_winner |>
  ggplot(aes( x = x, y = y)) +
  geom_tile(color = "black",
            fill = "green") +
   geom_point(data= cow_grid_winner |> filter(winner),
            color = "brown",
            size = 5,
            shape = "X")
```

```{r}
cow_grid_winner <- cow_patty_bingo_lazy(seed = 2)

cow_grid_winner |>
  ggplot(aes( x = x, y = y)) +
  geom_tile(color = "black",
            fill = "green") +
   geom_point(data= cow_grid_winner |> filter(winner),
            color = "brown",
            size = 5,
            shape = "X")
```

```{r}
cow_grid_winner <- cow_patty_bingo_lazy(seed = 3)

cow_grid_winner |>
  ggplot(aes( x = x, y = y)) +
  geom_tile(color = "black",
            fill = "green") +
   geom_point(data= cow_grid_winner |> filter(winner),
            color = "brown",
            size = 5,
            shape = "X")
```

### Part C [10 Points]

Make a plot demonstrating the relative number of times each square was chosen in 1000 simulations.

```{r}
cow_trials <- tibble(trial_num = 1:100) |>
  rowwise()|>
  mutate(cow_trial = list(cow_patty_bingo_lazy(seed = trial_num)))

cow_trials_results <- cow_trials |>
  unnest(cow_trial) |>
  summarize(n_wins = sum(winner),
            .by = c(square_id, x, y))

cow_trials_results |>
  ggplot(aes( x = x, y = y)) +
  geom_tile(aes(fill = n_wins),
            color = "black") +
  scale_fill_gradient(low = "green",
                      high = "brown")
```

How often does our square (square 42) get chosen? 

```{r}
cow_trials_results_ours <- cow_trials_results |>
  filter(square_id == 42)

cow_trials_results_ours$n_wins
```


### Part D [20 Points]

A lazy cow is allowed to to its business twice. Which of the following two scenarios are more likely?

-   The two chosen squares have an odd value for both x and y.

-   The two chosen squares are immediately adjacent to each other (including diagonals), but not the same square. Examples: {(0,1) and (0,2)}, {(4,3) and (5,4)}, {(3,4) and (2,3)}.

Use simulation to justify your answer.

```{r}
cow_patty_bingo_lazy_two <- function(seed){
  set.seed(seed)
  
  cow_grid <- expand_grid(x = 1:10,
                        y = 1:10) |>
  mutate(square_id = 1:n(),
         .before = 1) |>
  mutate(prob2 = exp(1)^(-0.5 * sqrt(x^2 + y^2)))
  
  mult = 1 / sum(cow_grid$prob2)  
  
  cow_grid <- cow_grid |>
    mutate(prob2 = mult * prob2)

  winner1 <- cow_grid |>
    pull(square_id) |>
    sample(1,
           prob = cow_grid |> pull(prob2))
  
  winner2 <- cow_grid |>
    pull(square_id) |>
    sample(1,
           prob = cow_grid |> pull(prob2))
  
  cow_grid |>
    mutate(winner1 = if_else(square_id == winner1,
                            TRUE,
                            FALSE)) |>
   mutate(winner2 = if_else(square_id == winner2,
                            TRUE,
                            FALSE))
}
```

```{r}
cow_grid_winner <- cow_patty_bingo_lazy_two(seed = 1)

cow_grid_winner |>
  ggplot(aes( x = x, y = y)) +
  geom_tile(color = "black",
            fill = "green") +
   geom_point(data= cow_grid_winner |> filter(winner1),
            color = "brown",
            size = 5,
            shape = "X") + 
     geom_point(data= cow_grid_winner |> filter(winner2),
            color = "brown",
            size = 5,
            shape = "O")
```
```{r}

cow_trials <- tibble(trial_num = 1:1000) |>
  rowwise()|>
  mutate(cow_trial = list(cow_patty_bingo_lazy_two(seed = trial_num)))

cow_trials_results <- cow_trials |>
  unnest(cow_trial) |>
  select(-c(square_id, prob2)) |>
  filter(winner1 == TRUE | winner2 == TRUE)
```

```{r}
result_odds <- cow_trials_results |>
  filter(x %% 2 == 1 & y %% 2 == 1) |>
  group_by(trial_num) |>
  filter(any(winner1) & any(winner2)) |>
  distinct(trial_num)

nrow(result_odds)
```
```{r}
adjacent <- function(x1, y1, x2, y2) {
  abs(x1 - x2) <= 1 & abs(y1 - y2) <= 1
}

result2 <- cow_trials_results |>
  group_by(trial_num) |>
  filter(n() == 2)

result2 <- result2 |>
  mutate(adjacent = ifelse(row_number() %% 2 == 0, adjacent(x, y, lag(x), lag(y)), NA)) |>
  filter(!is.na(adjacent))

sum(result2$adjacent == TRUE)
```
There were more adjacent winners than both double odd-numbered winners.



## Problem 2: [17 Points Total]

Recall the palmerpenguins dataset.

```{r}
library(palmerpenguins)

penguins |> 
  glimpse()
```

### Part A [12 Points]

Use a permutation test to assess whether or not Adelie penguins and Chinstrap penguins have the same mean flipper length.

```{r}
penguins_dat <- penguins |> 
  drop_na(flipper_length_mm) |>
  filter(species != "Gentoo")

summary_dat <- penguins_dat |>
  summarize(mean_length = mean(flipper_length_mm), 
            n_penguins = n(),
            .by = species)

Tobs <- summary_dat$mean_length[1] - summary_dat$mean_length[2] 

# Difference in sample mean length for two species
Tobs
```
```{r}
set.seed(7)
labels_permuted <- sample(penguins_dat$species, length(penguins_dat$species))
labels_permuted
```
```{r}
shuffle_penguins <- function(seed,
                             penguins_dat){
  set.seed(seed)
  
  penguins_dat |>
    mutate(labels_permuted = sample(penguins_dat$species, length(penguins_dat$species)))
}

permutation_penguins <- tibble(simulation_num = 1:500) |>
  rowwise() |>
  mutate(shuffled_df = list(shuffle_penguins(simulation_num,
                                             penguins_dat)))

permutation_penguins <- permutation_penguins |>
  mutate(mean_length_Adelie = shuffled_df |>
           filter(labels_permuted == "Adelie") |>
           pull(flipper_length_mm) |>
           mean()) |>
  mutate(mean_length_Chinstrap = shuffled_df |>
           filter(labels_permuted == "Chinstrap") |>
           pull(flipper_length_mm) |>
           mean()) |>
  mutate(mean_length_diff = mean_length_Adelie - mean_length_Chinstrap)

permutation_penguins |>
  mutate(type = "simulated") |>
  ggplot(aes(x = mean_length_diff,
             fill = type,
             color = type)) +
  geom_histogram() +
  geom_point(aes(fill = "Observed",
                 color = "Observed",
                 x = Tobs,
                 y = 0),
             shape = 21,
             size = 3)
```

It is apparent that the mean_length_diff we get is well outside what we would expect if the two distributions were the same. Therefore, we reject the null hypothesis and conclude that mean flipper lengths are different between Adelie and Chinstrap penguins. 

### Part B [5 Points]

Use a Kolmogorov-Smirnov test to assess whether Adelie Penguins and Chinstrap penguins have the same distribution for flipper length.

```{r}
x <- penguins |> 
  drop_na(flipper_length_mm) |>
  filter(species == "Adelie")

y <- penguins |> 
  drop_na(flipper_length_mm) |>
  filter(species == "Chinstrap")

x <- x$flipper_length_mm
y <- y$flipper_length_mm

# Null hypothesis is that distributions are the same, alternative is that they are not the same
ks.test(x, y)
```
The p-value is sufficiently small, giving us enough evidence to reject the null hypothesis and conclude that the distributions are different. 

## Problem 3: [40 Points Total]

Use random number simulation to solve the following problems.

### Part A: [15 Points]

Consider the functions:

$$ f(x) = x^2 \log(x)^2 $$

and

$$ g(x) = x^2 + \log(x)^2 $$

Suppose that $X$ follows a gamma distribution with shape parameter 2 and rate parameter 2. Is the expected value of $g(X)$ greater than the expected value of $f(X)$?

```{r}
nums <- rgamma(10000, shape = 2, rate = 3)

nums <- nums^2

nums <- nums * log(nums)^2

mean(nums)
```
```{r}
nums <- rgamma(10000, shape = 2, rate = 3)

nums <- nums^2

nums <- nums + log(nums)^2

mean(nums)
# g(x) is much larger than f(x), so its expected value is likely higher than f(x)
```


### Part B: [10 Points]

Suppose that $X$ follows a uniform(0,1) distribution. Use the Kolmogorov Smirnov test to assess whether $-\log(X)$ follows an exponential distribution with rate = 1. Use 10000 draws in your simulation.

```{r}
nums <- runif(10000, min = 0, max = 1)
nums <- -log(nums)
ks.test(nums, "pexp", rate = 1)
#alpha = 0.05
```
There is not enough evidence to reject the null hypothesis in this case. Therefore, we conclude that the -log(X) distribution follows an exponential distribution with rate = 1. 

### Part C: [15 Points]

We are a lightning insurance company pricing a policy for the dam. If the dam gets hit 0 or 1 times in a day, the dam will not break. However, if it gets hit 2 or more times, it will break and cause a flood, incurring a large cost.

Let $X$ denote the number of lightning strikes hitting the dam in a day. Suppose $X$ follows a Poisson distribution with mean $\lambda = 0.01$. In a given day, the lightning-related damage incurred by the dam has a cost of $C(X) = 1000 \times X(X-1)e^{-X}$. What is the expected cost of the damage to a dam in a day?

Please provide a confidence interval for your approximation. Ensure the confidence interval has a width smaller than one.

```{r}
set.seed(1)

x <- rpois(1000000, 0.01)
x <- ifelse(x >= 2, 1000 * x * (x-1) * exp(1)^(-x), 0)

print(paste("expectation =", mean(x)))
se = sd(x)/sqrt(length(x))
print(paste("lower bound =", mean(x) - 2 * se))
print(paste("upper bound =", mean(x) + 2 * se))
```
