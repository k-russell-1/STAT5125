---
title: "Homework 3"
author: Kevin Russell
format: 
  html:
    embed-resources: true
---

# Problem 1 [25 Points Total]

I have shared the_office_data.csv on HuskyCT. It is a dataset consisting of one row for each episode of the office.

## Part A [5 points]

Read the dataset into R.

```{r}
library(dplyr)
library(tidyverse)
library(ggplot2)
library(jpeg)
library(raster)
library(rvest)
```


```{r}
office <- read.csv("C:/Users/kruss/Downloads/the_office_data.csv")

office |>
  glimpse()

office
```

## Part B [10 Points]

Use the tidyverse to recreate the following bar chart displaying the number of episodes written by the top 10 most common "The Office" writers.

```{r}
writers <- office |>
  separate_longer_delim(writer, 
                        delim = ";") |>
  count(writer) |> 
  filter(n >= 10)

writers |>
  ggplot(aes(x = n, y = reorder(writer, n))) + 
  geom_bar(stat = "identity") +
  labs(x = "Number of Episodes", y = "Writer")
```

## Part C [10 Points]

Recreate the following plot displaying the number of office episodes originally aired in each month of the year.

```{r}
months <- office |>
    mutate(month = parse_number(sub(".*-(.*)-.*", "\\1", air_date))) |>
  count(month)

months |>
  ggplot(aes(x = month, y = n)) + 
  geom_bar(stat = "identity") +
  labs(x = "Airing Month Number", y = "Number of The Office Episodes") +
  scale_x_continuous(breaks=0:12) 
  

```


# Problem 2 [35 Points Total]

## Part A [15 Points]

On HuskyCT I have shared a zipped file of 9 jpg images, each depicting a handwritten digit 1-9. Use the readJPEG from the jpeg package to read in each of these images. Assemble them into a single tidy data frame with one row for each pixel in each image. 

Each image consists of 28 by 28 pixels, so in total the data frame should have 7056 rows. Columns should be x, y, value (for the pixel value), and digit (dictating which digit image it came from)

```{r}
digit_one <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_1.jpg")
digit_two <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_2.jpg")
digit_three <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_3.jpg")
digit_four <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_4.jpg")
digit_five <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_5.jpg")
digit_six <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_6.jpg")
digit_seven <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_7.jpg")
digit_eight <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_8.jpg")
digit_nine <- readJPEG("C:/Users/kruss/Downloads/digits/digits/img_9.jpg")

```

```{r}
one_data <- digit_one |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "1")|>
  dplyr::select(-name)

two_data <- digit_two |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "2") |>
  dplyr::select(-name)

three_data <- digit_three |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "3") |>
  dplyr::select(-name)

four_data <- digit_four |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "4") |>
  dplyr::select(-name)

five_data <- digit_five |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "5") |>
  dplyr::select(-name)

six_data <- digit_six |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "6") |>
  dplyr::select(-name)

seven_data <- digit_seven |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "7") |>
  dplyr::select(-name)

eight_data <- digit_eight |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "8") |>
  dplyr::select(-name)

nine_data <- digit_nine |>
  raster::as.data.frame()  |>
  pivot_longer(cols = starts_with("V")) |>
  mutate(x = parse_number(name),
         y = rep(28:1, each = 28),
         digit = "9") |>
  dplyr::select(-name)
```

```{r}
digits <- rbind(one_data, two_data, three_data, four_data, five_data, six_data, seven_data, eight_data, nine_data)
```


## Part B [5 Points]

Use the tidy data frame from part A to recreate the following faceted plot.

```{r}
digits |>
  ggplot(aes(x = x,
             y = y,
             fill = value)) + 
  geom_raster() +
  scale_fill_gradient(low = "white", 
                      high = "black")  +
  coord_fixed() + 
  facet_wrap(~ digit)
```

## Part C [5 Points]

List the digits in order of the sum of their pixel intensities (hint: 1 has the lowest, 5 has the highest.)

```{r}
digits |> 
  group_by(digit) |>
  summarise(intensity = sum(value)) |>
  arrange(desc(intensity))
```

## Part D [5 Points]

Recreate the following image that reflects the "average" image across the ten images.

```{r}
digits_avg <- digits |> 
  group_by(x, y) |>
  summarise(value = mean(value))

digits_avg |>
  ggplot(aes(x = x,
             y = y,
             fill = value)) + 
  geom_raster() +
  scale_fill_gradient(low = "white", 
                      high = "black")  +
  coord_fixed()
```

## Part E [5 Points]

Which pixel coordinate (x,y) value the highest average intensity across the ten digits?

```{r}
digits_avg |>
arrange(desc(value))
```


# Problem 3 [25 Points Total]

The wikipedia webpage on elections in Connecticut, available at https://en.wikipedia.org/wiki/Elections_in_Connecticut, provides a table titled United States presidential election results for Connecticut.

The problem steps are as follows:

- (A) use rvest to scrape this data from web,
- (B) use tidyverse and janitor functions to tidy it,
- (C) use ggplot2 to recreate the following plot.

## Part A [10 Points]

```{r}
results <- "https://en.wikipedia.org/wiki/Elections_in_Connecticut" |>
  read_html()

election_table <- html_table(results)
results <- election_table[[9]]
results
```

## Part B [10 Points]

```{r}
results <- results[-1,]
results
```

```{r}
results <- results |> 
  rename(republican_count = 2,
         republican_share = 3,
         democratic_count = 4,
         democratic_share = 5,
         third_party_count = 6,
         third_party_share = 7) |>
  mutate(share_republican = parse_number(republican_share),
         share_democratic = parse_number(democratic_share),
         share_third_party = parse_number(third_party_share)) |>
  dplyr::select(c(Year, share_republican, share_democratic, share_third_party)) |>
  pivot_longer(cols = starts_with("share")) |>
  mutate(Year = as.numeric(Year)) |>
  mutate(name = ifelse(name == "share_republican", "republican", ifelse(name == "share_democratic", "democratic", "third_party")))
results
```

## Part C [5 Points]

```{r}
results |>
    ggplot(aes(x = Year, y = value, color = name)) +
  geom_line() + 
  geom_point() +
  scale_color_manual(values = c("blue", "red", "dark green")) + 
  theme(legend.position="bottom") +
  labs(y = "Voting Share", x = "Election Year", color = "Party")
```


# Problem 4 [15 Points]

Use the readxl package to read in the data provided in State_to_State_Migrations_Table_2019.xls. Use janitor and tidyverse functions to clean and tidy this data. The result should match the format in state_network_moe.csv. 

Note that state_network_moe.csv contains even more information than the version we obtained as an example in class. Namely, it contains the margin of error (moe) for the movement estimates, and also includes Puerto Rico.

Note: I found this problem very challenging, but I want to expose you all to the difficulties of cleaning real datasets. Don't hesitate to reach out during office hours or brainstorm together with your peers. There are multiple ways to attack this problem; your final solution does not have to be elegant. 

Hint: the following is how my solution starts.

```{r}
library(readxl)
library(janitor)

# select a wider window of the excel file than we chose in class in order to include Puerto Rico.
raw_data <- read_excel("C:/Users/kruss/Downloads/State_to_State_Migrations_Table_2019(1).xls",
                     range = "J7:DV78")

# remove the annoying "Total" column that got added right before Puerto Rico.
raw_data <- raw_data |>
  dplyr::select(!c(Total, ...115))

# throw away the original headings and replace them with the first row
trying <- raw_data |>
  row_to_names(1) |>
  janitor::clean_names()

# rename the state_arrived column
trying <- trying |>
  rename(State_arrived = na) |>
  relocate(State_arrived, .before = 1)

trying <- as.data.frame(trying)
```
```{r}
target <- read_csv("C:/Users/kruss/Downloads/state_network_moe.csv")
```


```{r}
trying <- trying |>
  dplyr::select(-starts_with("na"))

trying <- trying |>
  mutate(State_arrived = ifelse(row_number() == 38, "State", State_arrived)) |>
  filter(!is.na(State_arrived)) |>
  filter(!is.na(estimate))
```


```{r}
# CODE VERIFYING THAT YOUR TIDY DATA MATCHES THAT OF state_network_moe.csv
```

IN THE CASE YOU ARE UNABLE TO FULLY COMPLETE THIS PROBLEM, DESCRIBE WHERE YOU GOT STUCK HERE, AND WHAT YOU WISHED YOU COULD DO TO GET AROUND IT [+3 BONUS POINTS].

I think at this point, if I could get the na's in the state row to be equal to the values before them, I could make two new df's, one dropping the moes and one dropping the estimates. Then I could pivot the tables so that the to and from state values were columns and the values were moe and estimate, respectively. Then I think I could join them on both state columns and get something resembling the final table. 

